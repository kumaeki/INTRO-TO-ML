{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62157ea",
   "metadata": {},
   "source": [
    "## Closed Form Solution (Analytic Solution)\n",
    "\n",
    "In order to minimize the mean squared error, we could use gradient descent or the tricks\n",
    "\n",
    "OR do this in a closed mathematical form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40ca86",
   "metadata": {},
   "source": [
    "### 2-Dimensional solution\n",
    "\n",
    "The mean squared error is \n",
    "\n",
    "$$E(w_1, w_2) = \\frac{1}{2m} \\sum_{i=1}^m ( \\hat{y} - y)^2$$\n",
    "\n",
    "we know\n",
    "\n",
    "$$  \\hat{y} = w_1x + w_2 $$\n",
    "\n",
    "so \n",
    "\n",
    "$$E(w_1, w_2) = \\frac{1}{2m} \\sum_{i=1}^m (w_1x_i + w_2 -  y_i)^2$$\n",
    "\n",
    "\n",
    "let's take the derivatives with respect to $w_1$ and $w_2$, and set them equal to 0\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w_1} = \\sum_{i=1}^m (w_1x_i + w_2 -  y_i)x_i = w_1 \\sum_{i=1}^m {x_i}^2 + w_2 \\sum_{i=1}^m x_i  -  \\sum_{i=1}^m x_iy_i = 0$$\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w_2} = \\sum_{i=1}^m (w_1x_i + w_2 -  y_i) = w_1 \\sum_{i=1}^m x_i + w_2 \\sum_{i=1}^m 1  -  \\sum_{i=1}^m y_i = w_1 \\sum_{i=1}^m x_i + w_2 m  -  \\sum_{i=1}^m y_i = 0$$\n",
    "\n",
    "We multipy the first equation by $m$ and the second one by $\\sum_{i=1}^m x_i$, subtract them to obtain a value for $w1$\n",
    "\n",
    "$$ w_1 =  \\frac{m(\\sum_{i=1}^m x_iy_i)-(\\sum_{i=1}^m x_i)(\\sum_{i=1}^m y_i)}{m(\\sum_{i=1}^m {x_i}^2) - {(\\sum_{i=1}^m x_i)}^2} $$\n",
    "\n",
    "and then replace this value in the first equation, obtain the value for $w_2$\n",
    "\n",
    "$$ w_2 =  \\frac{(\\sum_{i=1}^m {x_i}^2)(\\sum_{i=1}^m y_i)-(\\sum_{i=1}^m x_iy_i)(\\sum_{i=1}^m x_i)}{m(\\sum_{i=1}^m {x_i}^2) - {(\\sum_{i=1}^m x_i)}^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1174f33",
   "metadata": {},
   "source": [
    "### n-Dimensional solution\n",
    "\n",
    "Now, let's do this when our data has n dimensions.\n",
    "\n",
    "Our matix $X$ containing the data is the following, where each row is one of our datapoints, and $x^{(i)}_0$ to represent the bias\n",
    "\n",
    "$$ X = \\begin{pmatrix}\n",
    "{x^{(0)}_0}&{x^{(0)}_1}&{\\cdots}&{x^{(0)}_n}\\\\\n",
    "{x^{(1)}_0}&{x^{(1)}_1}&{\\cdots}&{x^{(1)}_n}\\\\\n",
    "{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\n",
    "{x^{(m)}_0}&{x^{(m)}_1}&{\\cdots}&{x^{(m)}_n}\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Our labels are the vector\n",
    "\n",
    "$$ y = \\begin{pmatrix}\n",
    "{y_0}\\\\\n",
    "{y_1}\\\\\n",
    "{\\vdots}\\\\\n",
    "{y_m}\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "and our weight matrix is the following\n",
    "\n",
    "$$ W = \\begin{pmatrix}\n",
    "{W_0}\\\\\n",
    "{W_1}\\\\\n",
    "{\\vdots}\\\\\n",
    "{W_n}\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "the equation for the mean square error can be written as the following matrix product\n",
    "\n",
    "$$E(W) = \\frac{1}{m}({(XW)}^T - y^T)(XW-y)$$\n",
    "\n",
    "expanding the equation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(W) \n",
    "&= \\frac{1}{m}(W^TX^TXW - {(XW)}^Ty - y^TXW + y^Ty) \\\\\n",
    "&= \\frac{1}{m}(W^TX^TXW - 2{(XW)}^Ty + y^Ty)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "take the derivative with respect to all W_i in the matrix W, we get\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E}{\\partial W} \n",
    "&= \\frac{\\partial (W^TX^TXW)}{\\partial W} - \\frac{\\partial (2{(XW)}^Ty)}{\\partial W} - \\frac{\\partial (y^Ty)}{\\partial W} \\\\\n",
    "&= \\frac{\\partial (W^TX^TX)}{\\partial W}W + W^T\\frac{\\partial (X^TXW)}{\\partial W} - \\frac{\\partial (2W^TX^Ty)}{\\partial W} - 0 \\\\\n",
    "&= X^TXW + W^TX^TX -2X^Ty \\\\\n",
    "&= 2X^TXW-2X^Ty\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Set this equals to zero, then we got our closed form solution for $W$\n",
    "\n",
    "$$2X^TXW-2X^Ty = 0$$\n",
    "\n",
    "$$W = \\frac{X^Ty}{X^TX}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "303fa613b6f3e1efefe7bb28036e305e1021fa6bdb083a5f9fd57f9d9bbad8eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
